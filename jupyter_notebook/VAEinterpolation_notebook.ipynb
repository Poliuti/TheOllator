{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DrumsVAEAugmentation.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZLfb2a_12wcj"
      },
      "source": [
        "# Environment Setup\n",
        "Includes package installation for sequence synthesis. Will take a few minutes.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hj0fXgEU9Vno"
      },
      "source": [
        "## Magenta setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PfRDVhNs3UFx",
        "outputId": "5ea9c684-4ede-404e-e7ef-3c6fd186c3c9"
      },
      "source": [
        "import glob\n",
        "\n",
        "BASE_DIR = \"gs://download.magenta.tensorflow.org/models/music_vae/colab2\"\n",
        "\n",
        "print('Installing dependencies...')\n",
        "!apt-get update -qq && apt-get install -qq libfluidsynth1 fluid-soundfont-gm build-essential libasound2-dev libjack-dev\n",
        "!pip install -q pyfluidsynth\n",
        "!pip install -qU magenta\n",
        "\n",
        "# Hack to allow python to pick up the newly-installed fluidsynth lib.\n",
        "# This is only needed for the hosted Colab environment.\n",
        "import ctypes.util\n",
        "orig_ctypes_util_find_library = ctypes.util.find_library\n",
        "def proxy_find_library(lib):\n",
        "  if lib == 'fluidsynth':\n",
        "    return 'libfluidsynth.so.1'\n",
        "  else:\n",
        "    return orig_ctypes_util_find_library(lib)\n",
        "ctypes.util.find_library = proxy_find_library\n",
        "\n",
        "\n",
        "print('Importing libraries and defining some helper functions...')\n",
        "from google.colab import files\n",
        "import magenta.music as mm\n",
        "from magenta.models.music_vae import configs\n",
        "from magenta.models.music_vae.trained_model import TrainedModel\n",
        "import numpy as np\n",
        "import os\n",
        "import tensorflow.compat.v1 as tf\n",
        "\n",
        "tf.disable_v2_behavior()\n",
        "\n",
        "# Necessary until pyfluidsynth is updated (>1.2.5).\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
        "\n",
        "def play(note_sequence):\n",
        "  mm.play_sequence(note_sequence, synth=mm.fluidsynth)\n",
        "\n",
        "def interpolate(model, start_seq, end_seq, num_steps, max_length=32,\n",
        "                assert_same_length=True, temperature=0.5,\n",
        "                individual_duration=4.0):\n",
        "  \"\"\"Interpolates between a start and end sequence.\"\"\"\n",
        "  note_sequences = model.interpolate(\n",
        "      start_seq, end_seq,num_steps=num_steps, length=max_length,\n",
        "      temperature=temperature,\n",
        "      assert_same_length=assert_same_length)\n",
        "\n",
        "  interp_seq = mm.sequences_lib.concatenate_sequences(\n",
        "      note_sequences, [individual_duration] * len(note_sequences))\n",
        "  return interp_seq if num_steps > 3 else note_sequences[num_steps // 2]\n",
        "\n",
        "def download(note_sequence, filename):\n",
        "  mm.sequence_proto_to_midi_file(note_sequence, filename)\n",
        "  files.download(filename)\n",
        "\n",
        "print('Done')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Installing dependencies...\n",
            "Selecting previously unselected package fluid-soundfont-gm.\n",
            "(Reading database ... 160772 files and directories currently installed.)\n",
            "Preparing to unpack .../fluid-soundfont-gm_3.1-5.1_all.deb ...\n",
            "Unpacking fluid-soundfont-gm (3.1-5.1) ...\n",
            "Selecting previously unselected package libfluidsynth1:amd64.\n",
            "Preparing to unpack .../libfluidsynth1_1.1.9-1_amd64.deb ...\n",
            "Unpacking libfluidsynth1:amd64 (1.1.9-1) ...\n",
            "Setting up fluid-soundfont-gm (3.1-5.1) ...\n",
            "Setting up libfluidsynth1:amd64 (1.1.9-1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.2) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.7/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n",
            "\u001b[K     |████████████████████████████████| 1.4MB 3.2MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.6MB 21.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 5.6MB 23.5MB/s \n",
            "\u001b[K     |████████████████████████████████| 92kB 9.3MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.5MB 34.1MB/s \n",
            "\u001b[K     |████████████████████████████████| 71kB 7.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 358kB 36.3MB/s \n",
            "\u001b[K     |████████████████████████████████| 256kB 31.5MB/s \n",
            "\u001b[K     |████████████████████████████████| 204kB 31.1MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.6MB 37.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 2.3MB 37.0MB/s \n",
            "\u001b[K     |████████████████████████████████| 215kB 38.0MB/s \n",
            "\u001b[K     |████████████████████████████████| 20.2MB 1.5MB/s \n",
            "\u001b[K     |████████████████████████████████| 655kB 35.5MB/s \n",
            "\u001b[K     |████████████████████████████████| 368kB 30.5MB/s \n",
            "\u001b[K     |████████████████████████████████| 81kB 8.3MB/s \n",
            "\u001b[K     |████████████████████████████████| 5.6MB 34.9MB/s \n",
            "\u001b[K     |████████████████████████████████| 194kB 46.1MB/s \n",
            "\u001b[K     |████████████████████████████████| 368kB 26.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 686kB 32.9MB/s \n",
            "\u001b[K     |████████████████████████████████| 256kB 33.7MB/s \n",
            "\u001b[?25h  Building wheel for pretty-midi (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for mir-eval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for python-rtmidi (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pygtrie (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for librosa (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for bz2file (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pypng (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: kfac 0.2.3 has requirement tensorflow-probability==0.8, but you'll have tensorflow-probability 0.12.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensor2tensor 1.15.7 has requirement tensorflow-probability==0.7.0, but you'll have tensorflow-probability 0.12.1 which is incompatible.\u001b[0m\n",
            "Importing libraries and defining some helper functions...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/librosa/util/decorators.py:9: NumbaDeprecationWarning: An import was requested from a module that has moved location.\n",
            "Import requested from: 'numba.decorators', please update to use 'numba.core.decorators' or pin to Numba version 0.48.0. This alias will not be present in Numba version 0.50.0.\n",
            "  from numba.decorators import jit as optional_jit\n",
            "/usr/local/lib/python3.7/dist-packages/librosa/util/decorators.py:9: NumbaDeprecationWarning: An import was requested from a module that has moved location.\n",
            "Import of 'jit' requested from: 'numba.decorators', please update to use 'numba.core.decorators' or pin to Numba version 0.48.0. This alias will not be present in Numba version 0.50.0.\n",
            "  from numba.decorators import jit as optional_jit\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n",
            "Done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C_TD5psbv9Ax"
      },
      "source": [
        "# 2-Bar Drums Model\n",
        "\n",
        "Below are 4 pre-trained models to experiment with. The first 3 map the 61 MIDI drum \"pitches\" to a reduced set of 9 classes (bass, snare, closed hi-hat, open hi-hat, low tom, mid tom, high tom, crash cymbal, ride cymbal) for a simplified but less expressive output space. The last model uses a [NADE](http://homepages.inf.ed.ac.uk/imurray2/pub/11nade/) to represent all possible MIDI drum \"pitches\".\n",
        "\n",
        "* **drums_2bar_oh_lokl**: This *low* KL model was trained for more *realistic* sampling. The output is a one-hot encoding of 2^9 combinations of hits. It has a single-layer bidirectional LSTM encoder with 512 nodes in each direction, a 2-layer LSTM decoder with 256 nodes in each layer, and a Z with 256 dimensions. During training it was given 0 free bits, and had a fixed beta value of 0.8. After 300k steps, the final accuracy is 0.73 and KL divergence is 11 bits.\n",
        "* **drums_2bar_oh_hikl**: This *high* KL model was trained for *better reconstruction and interpolation*. The output is a one-hot encoding of 2^9 combinations of hits. It has a single-layer bidirectional LSTM encoder with 512 nodes in each direction, a 2-layer LSTM decoder with 256 nodes in each layer, and a Z with 256 dimensions. During training it was given 96 free bits and had a fixed beta value of 0.2. It was trained with scheduled sampling with an inverse sigmoid schedule and a rate of 1000. After 300k, steps the final accuracy is 0.97 and KL divergence is 107 bits.\n",
        "* **drums_2bar_nade_reduced**: This model outputs a multi-label \"pianoroll\" with 9 classes. It has a single-layer bidirectional LSTM encoder with 512 nodes in each direction, a 2-layer LSTM-NADE decoder with 512 nodes in each layer and 9-dimensional NADE with 128 hidden units, and a Z with 256 dimensions. During training it was given 96 free bits and has a fixed beta value of 0.2. It was trained with scheduled sampling with an inverse sigmoid schedule and a rate of 1000. After 300k steps, the final accuracy is 0.98 and KL divergence is 110 bits.\n",
        "* **drums_2bar_nade_full**:  The output is a multi-label \"pianoroll\" with 61 classes. A single-layer bidirectional LSTM encoder with 512 nodes in each direction, a 2-layer LSTM-NADE decoder with 512 nodes in each layer and 61-dimensional NADE with 128 hidden units, and a Z with 256 dimensions. During training it was given 0 free bits and has a fixed beta value of 0.2. It was trained with scheduled sampling with an inverse sigmoid schedule and a rate of 1000. After 300k steps, the final accuracy is 0.90 and KL divergence is 116 bits."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AtklSbTtL9JY"
      },
      "source": [
        "#Load Pretrained Models\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0x8YTRDwv8Gk",
        "outputId": "5e3260f4-9b4e-442d-8df2-d1715d3542b2"
      },
      "source": [
        "drums_models = {}\n",
        "# One-hot encoded.\n",
        "drums_config = configs.CONFIG_MAP['cat-drums_2bar_small']\n",
        "drums_models['drums_2bar_oh_lokl'] = TrainedModel(drums_config, batch_size=4, checkpoint_dir_or_path=BASE_DIR + '/checkpoints/drums_2bar_small.lokl.ckpt')\n",
        "drums_models['drums_2bar_oh_hikl'] = TrainedModel(drums_config, batch_size=4, checkpoint_dir_or_path=BASE_DIR + '/checkpoints/drums_2bar_small.hikl.ckpt')\n",
        "\n",
        "# Multi-label NADE.\n",
        "drums_nade_reduced_config = configs.CONFIG_MAP['nade-drums_2bar_reduced']\n",
        "drums_models['drums_2bar_nade_reduced'] = TrainedModel(drums_nade_reduced_config, batch_size=4, checkpoint_dir_or_path=BASE_DIR + '/checkpoints/drums_2bar_nade.reduced.ckpt')\n",
        "drums_nade_full_config = configs.CONFIG_MAP['nade-drums_2bar_full']\n",
        "drums_models['drums_2bar_nade_full'] = TrainedModel(drums_nade_full_config, batch_size=4, checkpoint_dir_or_path=BASE_DIR + '/checkpoints/drums_2bar_nade.full.ckpt')\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Building MusicVAE model with BidirectionalLstmEncoder, CategoricalLstmDecoder, and hparams:\n",
            "{'max_seq_len': 32, 'z_size': 256, 'free_bits': 48, 'max_beta': 0.2, 'beta_rate': 0.0, 'batch_size': 4, 'grad_clip': 1.0, 'clip_mode': 'global_norm', 'grad_norm_clip_to_zero': 10000, 'learning_rate': 0.001, 'decay_rate': 0.9999, 'min_learning_rate': 1e-05, 'conditional': True, 'dec_rnn_size': [256, 256], 'enc_rnn_size': [512], 'dropout_keep_prob': 1.0, 'sampling_schedule': 'inverse_sigmoid', 'sampling_rate': 1000, 'use_cudnn': False, 'residual_encoder': False, 'residual_decoder': False, 'control_preprocessing_rnn_size': [256]}\n",
            "INFO:tensorflow:\n",
            "Encoder Cells (bidirectional):\n",
            "  units: [512]\n",
            "\n",
            "WARNING:tensorflow:`tf.nn.rnn_cell.MultiRNNCell` is deprecated. This class is equivalent as `tf.keras.layers.StackedRNNCells`, and will be replaced by that in Tensorflow 2.0.\n",
            "WARNING:tensorflow:`tf.nn.rnn_cell.MultiRNNCell` is deprecated. This class is equivalent as `tf.keras.layers.StackedRNNCells`, and will be replaced by that in Tensorflow 2.0.\n",
            "INFO:tensorflow:\n",
            "Decoder Cells:\n",
            "  units: [256, 256]\n",
            "\n",
            "WARNING:tensorflow:Setting non-training sampling schedule from inverse_sigmoid:1000.000000 to constant:1.0.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/magenta/models/music_vae/lstm_utils.py:145: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "WARNING:tensorflow:`tf.nn.rnn_cell.MultiRNNCell` is deprecated. This class is equivalent as `tf.keras.layers.StackedRNNCells`, and will be replaced by that in Tensorflow 2.0.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/legacy_tf_layers/core.py:171: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
            "  warnings.warn('`tf.layers.dense` is deprecated and '\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer_v1.py:1692: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
            "  warnings.warn('`layer.apply` is deprecated and '\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer_v1.py:1700: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n",
            "  warnings.warn('`layer.add_variable` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/magenta/contrib/rnn.py:474: bidirectional_dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `keras.layers.Bidirectional(keras.layers.RNN(cell))`, which is equivalent to this API\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/rnn.py:447: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
            "INFO:tensorflow:Restoring parameters from gs://download.magenta.tensorflow.org/models/music_vae/colab2/checkpoints/drums_2bar_small.lokl.ckpt\n",
            "INFO:tensorflow:Building MusicVAE model with BidirectionalLstmEncoder, CategoricalLstmDecoder, and hparams:\n",
            "{'max_seq_len': 32, 'z_size': 256, 'free_bits': 48, 'max_beta': 0.2, 'beta_rate': 0.0, 'batch_size': 4, 'grad_clip': 1.0, 'clip_mode': 'global_norm', 'grad_norm_clip_to_zero': 10000, 'learning_rate': 0.001, 'decay_rate': 0.9999, 'min_learning_rate': 1e-05, 'conditional': True, 'dec_rnn_size': [256, 256], 'enc_rnn_size': [512], 'dropout_keep_prob': 1.0, 'sampling_schedule': 'inverse_sigmoid', 'sampling_rate': 1000, 'use_cudnn': False, 'residual_encoder': False, 'residual_decoder': False, 'control_preprocessing_rnn_size': [256]}\n",
            "INFO:tensorflow:\n",
            "Encoder Cells (bidirectional):\n",
            "  units: [512]\n",
            "\n",
            "WARNING:tensorflow:`tf.nn.rnn_cell.MultiRNNCell` is deprecated. This class is equivalent as `tf.keras.layers.StackedRNNCells`, and will be replaced by that in Tensorflow 2.0.\n",
            "WARNING:tensorflow:`tf.nn.rnn_cell.MultiRNNCell` is deprecated. This class is equivalent as `tf.keras.layers.StackedRNNCells`, and will be replaced by that in Tensorflow 2.0.\n",
            "INFO:tensorflow:\n",
            "Decoder Cells:\n",
            "  units: [256, 256]\n",
            "\n",
            "WARNING:tensorflow:Setting non-training sampling schedule from inverse_sigmoid:1000.000000 to constant:1.0.\n",
            "WARNING:tensorflow:`tf.nn.rnn_cell.MultiRNNCell` is deprecated. This class is equivalent as `tf.keras.layers.StackedRNNCells`, and will be replaced by that in Tensorflow 2.0.\n",
            "INFO:tensorflow:Restoring parameters from gs://download.magenta.tensorflow.org/models/music_vae/colab2/checkpoints/drums_2bar_small.hikl.ckpt\n",
            "INFO:tensorflow:Building MusicVAE model with BidirectionalLstmEncoder, MultiLabelRnnNadeDecoder, and hparams:\n",
            "{'max_seq_len': 32, 'z_size': 256, 'free_bits': 48, 'max_beta': 0.2, 'beta_rate': 0.0, 'batch_size': 4, 'grad_clip': 1.0, 'clip_mode': 'global_norm', 'grad_norm_clip_to_zero': 10000, 'learning_rate': 0.001, 'decay_rate': 0.9999, 'min_learning_rate': 1e-05, 'conditional': True, 'dec_rnn_size': [512, 512], 'enc_rnn_size': [1024], 'dropout_keep_prob': 1.0, 'sampling_schedule': 'inverse_sigmoid', 'sampling_rate': 1000, 'use_cudnn': False, 'residual_encoder': False, 'residual_decoder': False, 'control_preprocessing_rnn_size': [256], 'nade_num_hidden': 128}\n",
            "INFO:tensorflow:\n",
            "Encoder Cells (bidirectional):\n",
            "  units: [1024]\n",
            "\n",
            "WARNING:tensorflow:`tf.nn.rnn_cell.MultiRNNCell` is deprecated. This class is equivalent as `tf.keras.layers.StackedRNNCells`, and will be replaced by that in Tensorflow 2.0.\n",
            "WARNING:tensorflow:`tf.nn.rnn_cell.MultiRNNCell` is deprecated. This class is equivalent as `tf.keras.layers.StackedRNNCells`, and will be replaced by that in Tensorflow 2.0.\n",
            "INFO:tensorflow:\n",
            "Decoder Cells:\n",
            "  units: [512, 512]\n",
            "\n",
            "WARNING:tensorflow:Setting non-training sampling schedule from inverse_sigmoid:1000.000000 to constant:1.0.\n",
            "WARNING:tensorflow:`tf.nn.rnn_cell.MultiRNNCell` is deprecated. This class is equivalent as `tf.keras.layers.StackedRNNCells`, and will be replaced by that in Tensorflow 2.0.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206: calling squeeze (from tensorflow.python.ops.array_ops) with squeeze_dims is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use the `axis` argument instead\n",
            "INFO:tensorflow:Restoring parameters from gs://download.magenta.tensorflow.org/models/music_vae/colab2/checkpoints/drums_2bar_nade.reduced.ckpt\n",
            "INFO:tensorflow:Building MusicVAE model with BidirectionalLstmEncoder, MultiLabelRnnNadeDecoder, and hparams:\n",
            "{'max_seq_len': 32, 'z_size': 256, 'free_bits': 48, 'max_beta': 0.2, 'beta_rate': 0.0, 'batch_size': 4, 'grad_clip': 1.0, 'clip_mode': 'global_norm', 'grad_norm_clip_to_zero': 10000, 'learning_rate': 0.001, 'decay_rate': 0.9999, 'min_learning_rate': 1e-05, 'conditional': True, 'dec_rnn_size': [512, 512], 'enc_rnn_size': [1024], 'dropout_keep_prob': 1.0, 'sampling_schedule': 'inverse_sigmoid', 'sampling_rate': 1000, 'use_cudnn': False, 'residual_encoder': False, 'residual_decoder': False, 'control_preprocessing_rnn_size': [256], 'nade_num_hidden': 128}\n",
            "INFO:tensorflow:\n",
            "Encoder Cells (bidirectional):\n",
            "  units: [1024]\n",
            "\n",
            "WARNING:tensorflow:`tf.nn.rnn_cell.MultiRNNCell` is deprecated. This class is equivalent as `tf.keras.layers.StackedRNNCells`, and will be replaced by that in Tensorflow 2.0.\n",
            "WARNING:tensorflow:`tf.nn.rnn_cell.MultiRNNCell` is deprecated. This class is equivalent as `tf.keras.layers.StackedRNNCells`, and will be replaced by that in Tensorflow 2.0.\n",
            "INFO:tensorflow:\n",
            "Decoder Cells:\n",
            "  units: [512, 512]\n",
            "\n",
            "WARNING:tensorflow:Setting non-training sampling schedule from inverse_sigmoid:1000.000000 to constant:1.0.\n",
            "WARNING:tensorflow:`tf.nn.rnn_cell.MultiRNNCell` is deprecated. This class is equivalent as `tf.keras.layers.StackedRNNCells`, and will be replaced by that in Tensorflow 2.0.\n",
            "INFO:tensorflow:Restoring parameters from gs://download.magenta.tensorflow.org/models/music_vae/colab2/checkpoints/drums_2bar_nade.full.ckpt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "77Aew5W5_Tof"
      },
      "source": [
        "# Download & Extract midi (1-time only)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5g3jjDIX9kiJ",
        "outputId": "86abc1ac-0238-4bf1-c22e-025735c76898"
      },
      "source": [
        "!rm -r midifiles\n",
        "\n",
        "os.mkdir('midifiles')\n",
        "!wget --no-check-certificate -r \"https://ollaregang.pythonanywhere.com/static/MIDI/AllDrums.zip\" -O \"midifiles/Input.zip\" "
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rm: cannot remove 'midifiles': No such file or directory\n",
            "WARNING: combining -O with -r or -p will mean that all downloaded content\n",
            "will be placed in the single file you specified.\n",
            "\n",
            "--2021-06-10 10:07:39--  https://ollaregang.pythonanywhere.com/static/MIDI/AllDrums.zip\n",
            "Resolving ollaregang.pythonanywhere.com (ollaregang.pythonanywhere.com)... 35.173.69.207\n",
            "Connecting to ollaregang.pythonanywhere.com (ollaregang.pythonanywhere.com)|35.173.69.207|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 7188 (7.0K) [application/zip]\n",
            "Saving to: ‘midifiles/Input.zip’\n",
            "\n",
            "midifiles/Input.zip 100%[===================>]   7.02K  --.-KB/s    in 0s      \n",
            "\n",
            "2021-06-10 10:07:39 (1001 MB/s) - ‘midifiles/Input.zip’ saved [7188/7188]\n",
            "\n",
            "FINISHED --2021-06-10 10:07:39--\n",
            "Total wall clock time: 0.4s\n",
            "Downloaded: 1 files, 7.0K in 0s (1001 MB/s)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ed5jiuB_nVr"
      },
      "source": [
        "from zipfile import ZipFile\n",
        "\n",
        "zipname = \"midifiles/Input.zip\"\n",
        "with ZipFile(zipname,'r') as zpfile:\n",
        "  files = zpfile.namelist()\n",
        "  for f in files:\n",
        "    if (f.endswith('.mid')):\n",
        "      zpfile.extract(f, 'midifiles')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RTsrpipz4cFc"
      },
      "source": [
        "# Generate Interpolations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a4uHE57PD5AS"
      },
      "source": [
        "## Load midi files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MnEZ1F7fAx0k"
      },
      "source": [
        "input_drums_midi_data = [\n",
        "    tf.io.gfile.GFile(fn, mode='rb').read()\n",
        "    for fn in sorted(tf.io.gfile.glob('./midifiles/MIDI_2bar/*.mid'))]"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5iWJ86wRJLpq"
      },
      "source": [
        "## Convert midi to needed format"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LJwe3BkPyg0H",
        "outputId": "0192ca30-43dc-476d-a41e-14c80285da6b"
      },
      "source": [
        "!rm -r midifiles/converted_MIDI\n",
        "!rm -r midifiles/interpolation_sequences"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rm: cannot remove 'midifiles/converted_MIDI': No such file or directory\n",
            "rm: cannot remove 'midifiles/interpolation_sequences': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zqCJFtHYb-7A"
      },
      "source": [
        "from note_seq.protobuf import music_pb2\n",
        "import copy\n",
        "import note_seq\n",
        "\n",
        "alphabet = [\"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\", \"H\", \"I\", \"J\"]\n",
        "\n",
        "os.mkdir('midifiles/converted_MIDI')\n",
        "os.mkdir('midifiles/interpolation_sequences')\n",
        "\n",
        "drums_input_seqs =music_pb2.NoteSequence();\n",
        "def set_to_drums(ns):\n",
        "  for n in ns.notes:\n",
        "    n.instrument=9\n",
        "    n.is_drum = True\n",
        "  return ns\n",
        "\n",
        "\n",
        "def midi_to_drum_note(input_drums_midi_data):\n",
        "  drums = []\n",
        "  for m in input_drums_midi_data:\n",
        "    drum = mm.midi_to_note_sequence(m)\n",
        "    set_to_drums(drum)\n",
        "    drums.append(drum)\n",
        "  return drums\n",
        "\n",
        "drums_input_seqs = midi_to_drum_note(input_drums_midi_data)\n",
        "\n",
        "for index in range(len(drums_input_seqs)):\n",
        "  midi_path = \"midifiles/converted_MIDI/converted_\" + alphabet[index] + \".mid\"\n",
        "  mm.note_sequence_to_midi_file(drums_input_seqs[index], midi_path)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kbW_rDWkJAfX"
      },
      "source": [
        "input_drums_midi_data = [\n",
        "    tf.io.gfile.GFile(fn, mode='rb').read()\n",
        "    for fn in sorted(tf.io.gfile.glob('./midifiles/converted_MIDI/*.mid'))]"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dac1r3kAJUaX"
      },
      "source": [
        "##Load & Listen beats"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 638
        },
        "id": "ilS5cJslHWcm",
        "outputId": "e9e913b1-550f-41cb-d5e1-4e9028075ec0"
      },
      "source": [
        "drums_input_seqs = [mm.midi_to_sequence_proto(m) for m in input_drums_midi_data]\n",
        "\n",
        "extracted_beats = [];\n",
        "for ns in drums_input_seqs:\n",
        "\n",
        "  test=drums_nade_full_config.data_converter.from_tensors(\n",
        "      drums_nade_full_config.data_converter.to_tensors(ns)[1])\n",
        "  extracted_beats.extend(test)\n",
        "  #print(test)\n",
        "for index, beat in enumerate(extracted_beats):\n",
        "  print(\"Beat\", index)\n",
        "  play(beat)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Beat 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div id=\"id_1\"> </div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Beat 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div id=\"id_2\"> </div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Beat 2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div id=\"id_3\"> </div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Beat 3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div id=\"id_4\"> </div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Beat 4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div id=\"id_5\"> </div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Beat 5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div id=\"id_6\"> </div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Beat 6\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div id=\"id_7\"> </div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Beat 7\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div id=\"id_8\"> </div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Beat 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div id=\"id_9\"> </div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Beat 9\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div id=\"id_10\"> </div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N0nNsM7yKR1b"
      },
      "source": [
        "## Interpolation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MeAboOS1xDgE",
        "outputId": "8cc55fb4-7bbb-49a2-c6f3-5075958c7a7e"
      },
      "source": [
        "drums_interp_model = \"drums_2bar_oh_hikl\" \n",
        "\n",
        "# temperature = 0.8 #@param {type:\"slider\", min:0.1, max:1.5, step:0.1}\n",
        "temperature = 0.5\n",
        "num_steps = 8 \n",
        "\n",
        "for index1, beat1 in enumerate(extracted_beats):\n",
        "  for index2, beat2 in enumerate(extracted_beats):\n",
        "    start_beat = extracted_beats[index1]\n",
        "    end_beat = extracted_beats[index2]\n",
        "    drums_interp = interpolate(drums_models[drums_interp_model],\n",
        "                              start_beat, \n",
        "                              end_beat, \n",
        "                              num_steps=num_steps, \n",
        "                              temperature=temperature)\n",
        "    mm.sequence_proto_to_midi_file(drums_interp, \"midifiles/interpolation_sequences/interpolation_\" + alphabet[index1] + alphabet[index2] + \".mid\")\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/magenta/models/music_vae/trained_model.py:384: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  return np.sin((1.0-t)*omega) / so * p0 + np.sin(t*omega)/so * p1\n",
            "/usr/local/lib/python3.7/dist-packages/magenta/models/music_vae/trained_model.py:382: RuntimeWarning: invalid value encountered in arccos\n",
            "  np.squeeze(p1/np.linalg.norm(p1))))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YebxxqJC7_5g"
      },
      "source": [
        "## Concatenate midi"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "61dzLm240A3i"
      },
      "source": [
        "os.mkdir('midifiles/temp_concatenations')\n",
        "os.mkdir('midifiles/final_concatenations')"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cGbsGqJPBRYW"
      },
      "source": [
        "from mido import MidiFile\n",
        "from mido import MidiTrack\n",
        "from mido import MetaMessage\n",
        "\n",
        "\n",
        "def concatenate_beats0(path1, path2, resolution1, resolution2, save_path):\n",
        "\n",
        "  mid0 = MidiFile()\n",
        "  mid0.ticks_per_beat=resolution1\n",
        "  track0 = MidiTrack()\n",
        "  mid0.tracks.append(track0)\n",
        "\n",
        "  mid = MidiFile(path1)\n",
        "\n",
        "  for msg in mid.tracks[2]:\n",
        "      mid0.tracks[0].append(msg)\n",
        "\n",
        "  mid2 = MidiFile(path2)\n",
        "\n",
        "  for msg in mid2.tracks[2][:-1]:\n",
        "      msg.time=int(msg.time*resolution1/resolution2)\n",
        "      mid0.tracks[0].append(msg)\n",
        "\n",
        "  mid0.save(save_path)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tVMyOjt7J49c"
      },
      "source": [
        "def concatenate_beats1(path1, path2, resolution1, resolution2, save_path):\n",
        "\n",
        "  mid0 = MidiFile()\n",
        "  mid0.ticks_per_beat=resolution1\n",
        "  track0 = MidiTrack()\n",
        "  mid0.tracks.append(track0)\n",
        "\n",
        "  mid = MidiFile(path1)\n",
        "\n",
        "  for msg in mid.tracks[0]:\n",
        "      mid0.tracks[0].append(msg)\n",
        "\n",
        "  mid2 = MidiFile(path2)\n",
        "\n",
        "  for msg in mid2.tracks[2][:-1]:\n",
        "      msg.time=int(msg.time*resolution1/resolution2)\n",
        "      mid0.tracks[0].append(msg)\n",
        "\n",
        "  mid0.save(save_path)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qbUMr7p7J7rr"
      },
      "source": [
        "def concatenate_beats2(path1, path2, resolution1, resolution2, save_path):\n",
        "\n",
        "  mid0 = MidiFile()\n",
        "  mid0.ticks_per_beat=resolution1\n",
        "  track0 = MidiTrack()\n",
        "  mid0.tracks.append(track0)\n",
        "\n",
        "  mid = MidiFile(path1)\n",
        "  for msg in mid.tracks[0]:\n",
        "      mid0.tracks[0].append(msg)\n",
        "\n",
        "  mid2 = MidiFile(path2)\n",
        "\n",
        "  for msg in mid2.tracks[0][:-1]:\n",
        "      msg.time=int(msg.time*resolution1/resolution2)\n",
        "      mid0.tracks[0].append(msg)\n",
        "\n",
        "  mid0.save(save_path)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sqy5y4JwNLUv"
      },
      "source": [
        "##Start concatenations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dci382ddptaX"
      },
      "source": [
        "for letter in alphabet:\n",
        "  concatenate_beats0(\"/content/midifiles/converted_MIDI/converted_\"+ letter + \".mid\",\n",
        "                    \"/content/midifiles/converted_MIDI/converted_\"+ letter + \".mid\",\n",
        "                    96,\n",
        "                    96,\n",
        "                    '/content/midifiles/temp_concatenations/longer_midi_' + letter + '.mid')"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vTrRNdWVjHNb"
      },
      "source": [
        "for letter1 in alphabet:\n",
        "  for letter2 in alphabet:\n",
        "    if letter1 != letter2:\n",
        "      concatenate_beats1(\"/content/midifiles/temp_concatenations/longer_midi_\"+ letter1 + \".mid\",\n",
        "                        \"/content/midifiles/interpolation_sequences/interpolation_\" + letter1 + letter2 + \".mid\",\n",
        "                        96,220,\n",
        "                        \"/content/midifiles/temp_concatenations/intermediate1_\" + letter1 + letter2 + \".mid\")\n",
        "      \n",
        "      concatenate_beats2(\"/content/midifiles/temp_concatenations/intermediate1_\"+ letter1 + letter2 + \".mid\",\n",
        "                        \"/content/midifiles/temp_concatenations/longer_midi_\"+ letter2 + \".mid\",\n",
        "                        96,96,\n",
        "                        \"/content/midifiles/temp_concatenations/intermediate2_\" + letter1 + letter2 + \".mid\")\n",
        "      \n",
        "      concatenate_beats1(\"/content/midifiles/temp_concatenations/intermediate2_\"+ letter1 + letter2 + \".mid\",\n",
        "                        \"/content/midifiles/interpolation_sequences/interpolation_\" + letter2 + letter1 + \".mid\",\n",
        "                        96,220,\n",
        "                        \"/content/midifiles/final_concatenations/interpolated_beat_\" + letter1 + letter2 + \".mid\")\n",
        "      "
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R_RXW95D9jg7"
      },
      "source": [
        "# Upload to server"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "SpEQ-nHUhhGx"
      },
      "source": [
        "import requests\n",
        "\n",
        "for letter1 in alphabet:\n",
        "  for letter2 in alphabet:\n",
        "    if letter1 != letter2:\n",
        "      url = 'http://OLLAREGANG.pythonanywhere.com/interpolationUploader/interpolation_' + letter1 + letter2 + \".mid\"\n",
        "      midiToUpload = open(\"/content/midifiles/final_concatenations/interpolated_beat_\" + letter1 + letter2 + \".mid\", 'rb')\n",
        "      x = requests.post(url, data = midiToUpload)\n",
        "      print(x.text)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}