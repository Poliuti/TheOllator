{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copia di MusicVAE.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "hYaJ6dvF0v7g",
        "R122bwRNbTus",
        "C_TD5psbv9Ax"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hYaJ6dvF0v7g"
      },
      "source": [
        "# MusicVAE: A Hierarchical Latent Vector Model for Learning Long-Term Structure in Music.\n",
        "### ___Adam Roberts, Jesse Engel, Colin Raffel, Curtis Hawthorne, and Douglas Eck___\n",
        "\n",
        "[MusicVAE](https://g.co/magenta/music-vae) learns a latent space of musical scores, providing different modes\n",
        "of interactive musical creation, including:\n",
        "\n",
        "* Random sampling from the prior distribution.\n",
        "* Interpolation between existing sequences.\n",
        "* Manipulation of existing sequences via attribute vectors.\n",
        "\n",
        "Examples of these interactions can be generated below, and selections can be heard in our\n",
        "[YouTube playlist](https://www.youtube.com/playlist?list=PLBUMAYA6kvGU8Cgqh709o5SUvo-zHGTxr).\n",
        "\n",
        "For short sequences (e.g., 2-bar \"loops\"), we use a bidirectional LSTM encoder\n",
        "and LSTM decoder. For longer sequences, we use a novel hierarchical LSTM\n",
        "decoder, which helps the model learn longer-term structures.\n",
        "\n",
        "We also model the interdependencies between instruments by training multiple\n",
        "decoders on the lowest-level embeddings of the hierarchical decoder.\n",
        "\n",
        "For additional details, check out our [blog post](https://g.co/magenta/music-vae) and [paper](https://goo.gl/magenta/musicvae-paper).\n",
        "___\n",
        "\n",
        "This colab notebook is self-contained and should run natively on google cloud. The [code](https://github.com/tensorflow/magenta/tree/master/magenta/models/music_vae) and [checkpoints](http://download.magenta.tensorflow.org/models/music_vae/checkpoints.tar.gz) can be downloaded separately and run locally, which is required if you want to train your own model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R122bwRNbTus"
      },
      "source": [
        "# Basic Instructions\n",
        "\n",
        "1. Double click on the hidden cells to make them visible, or select \"View > Expand Sections\" in the menu at the top.\n",
        "2. Hover over the \"`[ ]`\" in the top-left corner of each cell and click on the \"Play\" button to run it, in order.\n",
        "3. Listen to the generated samples.\n",
        "4. Make it your own: copy the notebook, modify the code, train your own models, upload your own MIDI, etc.!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZLfb2a_12wcj"
      },
      "source": [
        "# Environment Setup\n",
        "Includes package installation for sequence synthesis. Will take a few minutes.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PfRDVhNs3UFx",
        "outputId": "dc10c7a0-6b1f-4e60-ea6e-8b04db8a3578"
      },
      "source": [
        "import glob\n",
        "\n",
        "BASE_DIR = \"gs://download.magenta.tensorflow.org/models/music_vae/colab2\"\n",
        "\n",
        "print('Installing dependencies...')\n",
        "!apt-get update -qq && apt-get install -qq libfluidsynth1 fluid-soundfont-gm build-essential libasound2-dev libjack-dev\n",
        "!pip install -q pyfluidsynth\n",
        "!pip install -qU magenta\n",
        "\n",
        "# Hack to allow python to pick up the newly-installed fluidsynth lib.\n",
        "# This is only needed for the hosted Colab environment.\n",
        "import ctypes.util\n",
        "orig_ctypes_util_find_library = ctypes.util.find_library\n",
        "def proxy_find_library(lib):\n",
        "  if lib == 'fluidsynth':\n",
        "    return 'libfluidsynth.so.1'\n",
        "  else:\n",
        "    return orig_ctypes_util_find_library(lib)\n",
        "ctypes.util.find_library = proxy_find_library\n",
        "\n",
        "\n",
        "print('Importing libraries and defining some helper functions...')\n",
        "from google.colab import files\n",
        "import magenta.music as mm\n",
        "from magenta.models.music_vae import configs\n",
        "from magenta.models.music_vae.trained_model import TrainedModel\n",
        "import numpy as np\n",
        "import os\n",
        "import tensorflow.compat.v1 as tf\n",
        "\n",
        "tf.disable_v2_behavior()\n",
        "\n",
        "# Necessary until pyfluidsynth is updated (>1.2.5).\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
        "\n",
        "def play(note_sequence):\n",
        "  mm.play_sequence(note_sequence, synth=mm.fluidsynth)\n",
        "\n",
        "def interpolate(model, start_seq, end_seq, num_steps, max_length=32,\n",
        "                assert_same_length=True, temperature=0.5,\n",
        "                individual_duration=4.0):\n",
        "  \"\"\"Interpolates between a start and end sequence.\"\"\"\n",
        "  note_sequences = model.interpolate(\n",
        "      start_seq, end_seq,num_steps=num_steps, length=max_length,\n",
        "      temperature=temperature,\n",
        "      assert_same_length=assert_same_length)\n",
        "\n",
        "  interp_seq = mm.sequences_lib.concatenate_sequences(\n",
        "      note_sequences, [individual_duration] * len(note_sequences))\n",
        "  return interp_seq if num_steps > 3 else note_sequences[num_steps // 2]\n",
        "\n",
        "def download(note_sequence, filename):\n",
        "  mm.sequence_proto_to_midi_file(note_sequence, filename)\n",
        "  files.download(filename)\n",
        "\n",
        "print('Done')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Installing dependencies...\n",
            "Selecting previously unselected package fluid-soundfont-gm.\n",
            "(Reading database ... 160706 files and directories currently installed.)\n",
            "Preparing to unpack .../fluid-soundfont-gm_3.1-5.1_all.deb ...\n",
            "Unpacking fluid-soundfont-gm (3.1-5.1) ...\n",
            "Selecting previously unselected package libfluidsynth1:amd64.\n",
            "Preparing to unpack .../libfluidsynth1_1.1.9-1_amd64.deb ...\n",
            "Unpacking libfluidsynth1:amd64 (1.1.9-1) ...\n",
            "Setting up fluid-soundfont-gm (3.1-5.1) ...\n",
            "Setting up libfluidsynth1:amd64 (1.1.9-1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.2) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.7/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n",
            "\u001b[K     |████████████████████████████████| 1.4MB 7.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 92kB 9.3MB/s \n",
            "\u001b[K     |████████████████████████████████| 215kB 31.6MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.6MB 36.6MB/s \n",
            "\u001b[K     |████████████████████████████████| 2.3MB 34.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 358kB 35.7MB/s \n",
            "\u001b[K     |████████████████████████████████| 256kB 46.9MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.6MB 43.0MB/s \n",
            "\u001b[K     |████████████████████████████████| 204kB 36.2MB/s \n",
            "\u001b[K     |████████████████████████████████| 71kB 7.0MB/s \n",
            "\u001b[K     |████████████████████████████████| 5.6MB 21.5MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.5MB 32.3MB/s \n",
            "\u001b[K     |████████████████████████████████| 20.2MB 4.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 81kB 7.0MB/s \n",
            "\u001b[K     |████████████████████████████████| 368kB 53.9MB/s \n",
            "\u001b[K     |████████████████████████████████| 5.6MB 25.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 368kB 45.0MB/s \n",
            "\u001b[K     |████████████████████████████████| 194kB 39.9MB/s \n",
            "\u001b[K     |████████████████████████████████| 686kB 41.1MB/s \n",
            "\u001b[K     |████████████████████████████████| 655kB 44.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 256kB 53.1MB/s \n",
            "\u001b[?25h  Building wheel for mir-eval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pygtrie (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for librosa (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for python-rtmidi (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pretty-midi (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for bz2file (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pypng (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: kfac 0.2.3 has requirement tensorflow-probability==0.8, but you'll have tensorflow-probability 0.12.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensor2tensor 1.15.7 has requirement tensorflow-probability==0.7.0, but you'll have tensorflow-probability 0.12.1 which is incompatible.\u001b[0m\n",
            "Importing libraries and defining some helper functions...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/librosa/util/decorators.py:9: NumbaDeprecationWarning: An import was requested from a module that has moved location.\n",
            "Import requested from: 'numba.decorators', please update to use 'numba.core.decorators' or pin to Numba version 0.48.0. This alias will not be present in Numba version 0.50.0.\n",
            "  from numba.decorators import jit as optional_jit\n",
            "/usr/local/lib/python3.7/dist-packages/librosa/util/decorators.py:9: NumbaDeprecationWarning: An import was requested from a module that has moved location.\n",
            "Import of 'jit' requested from: 'numba.decorators', please update to use 'numba.core.decorators' or pin to Numba version 0.48.0. This alias will not be present in Numba version 0.50.0.\n",
            "  from numba.decorators import jit as optional_jit\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n",
            "Done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C_TD5psbv9Ax"
      },
      "source": [
        "# 2-Bar Drums Model\n",
        "\n",
        "Below are 4 pre-trained models to experiment with. The first 3 map the 61 MIDI drum \"pitches\" to a reduced set of 9 classes (bass, snare, closed hi-hat, open hi-hat, low tom, mid tom, high tom, crash cymbal, ride cymbal) for a simplified but less expressive output space. The last model uses a [NADE](http://homepages.inf.ed.ac.uk/imurray2/pub/11nade/) to represent all possible MIDI drum \"pitches\".\n",
        "\n",
        "* **drums_2bar_oh_lokl**: This *low* KL model was trained for more *realistic* sampling. The output is a one-hot encoding of 2^9 combinations of hits. It has a single-layer bidirectional LSTM encoder with 512 nodes in each direction, a 2-layer LSTM decoder with 256 nodes in each layer, and a Z with 256 dimensions. During training it was given 0 free bits, and had a fixed beta value of 0.8. After 300k steps, the final accuracy is 0.73 and KL divergence is 11 bits.\n",
        "* **drums_2bar_oh_hikl**: This *high* KL model was trained for *better reconstruction and interpolation*. The output is a one-hot encoding of 2^9 combinations of hits. It has a single-layer bidirectional LSTM encoder with 512 nodes in each direction, a 2-layer LSTM decoder with 256 nodes in each layer, and a Z with 256 dimensions. During training it was given 96 free bits and had a fixed beta value of 0.2. It was trained with scheduled sampling with an inverse sigmoid schedule and a rate of 1000. After 300k, steps the final accuracy is 0.97 and KL divergence is 107 bits.\n",
        "* **drums_2bar_nade_reduced**: This model outputs a multi-label \"pianoroll\" with 9 classes. It has a single-layer bidirectional LSTM encoder with 512 nodes in each direction, a 2-layer LSTM-NADE decoder with 512 nodes in each layer and 9-dimensional NADE with 128 hidden units, and a Z with 256 dimensions. During training it was given 96 free bits and has a fixed beta value of 0.2. It was trained with scheduled sampling with an inverse sigmoid schedule and a rate of 1000. After 300k steps, the final accuracy is 0.98 and KL divergence is 110 bits.\n",
        "* **drums_2bar_nade_full**:  The output is a multi-label \"pianoroll\" with 61 classes. A single-layer bidirectional LSTM encoder with 512 nodes in each direction, a 2-layer LSTM-NADE decoder with 512 nodes in each layer and 61-dimensional NADE with 128 hidden units, and a Z with 256 dimensions. During training it was given 0 free bits and has a fixed beta value of 0.2. It was trained with scheduled sampling with an inverse sigmoid schedule and a rate of 1000. After 300k steps, the final accuracy is 0.90 and KL divergence is 116 bits."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0x8YTRDwv8Gk",
        "outputId": "49183776-5f1c-49a0-cd63-24d48059c562"
      },
      "source": [
        "#@title Load Pretrained Models\n",
        "\n",
        "drums_models = {}\n",
        "# One-hot encoded.\n",
        "drums_config = configs.CONFIG_MAP['cat-drums_2bar_small']\n",
        "drums_models['drums_2bar_oh_lokl'] = TrainedModel(drums_config, batch_size=4, checkpoint_dir_or_path=BASE_DIR + '/checkpoints/drums_2bar_small.lokl.ckpt')\n",
        "drums_models['drums_2bar_oh_hikl'] = TrainedModel(drums_config, batch_size=4, checkpoint_dir_or_path=BASE_DIR + '/checkpoints/drums_2bar_small.hikl.ckpt')\n",
        "\n",
        "# Multi-label NADE.\n",
        "drums_nade_reduced_config = configs.CONFIG_MAP['nade-drums_2bar_reduced']\n",
        "drums_models['drums_2bar_nade_reduced'] = TrainedModel(drums_nade_reduced_config, batch_size=4, checkpoint_dir_or_path=BASE_DIR + '/checkpoints/drums_2bar_nade.reduced.ckpt')\n",
        "drums_nade_full_config = configs.CONFIG_MAP['nade-drums_2bar_full']\n",
        "drums_models['drums_2bar_nade_full'] = TrainedModel(drums_nade_full_config, batch_size=4, checkpoint_dir_or_path=BASE_DIR + '/checkpoints/drums_2bar_nade.full.ckpt')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Building MusicVAE model with BidirectionalLstmEncoder, CategoricalLstmDecoder, and hparams:\n",
            "{'max_seq_len': 32, 'z_size': 256, 'free_bits': 48, 'max_beta': 0.2, 'beta_rate': 0.0, 'batch_size': 4, 'grad_clip': 1.0, 'clip_mode': 'global_norm', 'grad_norm_clip_to_zero': 10000, 'learning_rate': 0.001, 'decay_rate': 0.9999, 'min_learning_rate': 1e-05, 'conditional': True, 'dec_rnn_size': [256, 256], 'enc_rnn_size': [512], 'dropout_keep_prob': 1.0, 'sampling_schedule': 'inverse_sigmoid', 'sampling_rate': 1000, 'use_cudnn': False, 'residual_encoder': False, 'residual_decoder': False, 'control_preprocessing_rnn_size': [256]}\n",
            "INFO:tensorflow:\n",
            "Encoder Cells (bidirectional):\n",
            "  units: [512]\n",
            "\n",
            "WARNING:tensorflow:`tf.nn.rnn_cell.MultiRNNCell` is deprecated. This class is equivalent as `tf.keras.layers.StackedRNNCells`, and will be replaced by that in Tensorflow 2.0.\n",
            "WARNING:tensorflow:`tf.nn.rnn_cell.MultiRNNCell` is deprecated. This class is equivalent as `tf.keras.layers.StackedRNNCells`, and will be replaced by that in Tensorflow 2.0.\n",
            "INFO:tensorflow:\n",
            "Decoder Cells:\n",
            "  units: [256, 256]\n",
            "\n",
            "WARNING:tensorflow:Setting non-training sampling schedule from inverse_sigmoid:1000.000000 to constant:1.0.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/magenta/models/music_vae/lstm_utils.py:145: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "WARNING:tensorflow:`tf.nn.rnn_cell.MultiRNNCell` is deprecated. This class is equivalent as `tf.keras.layers.StackedRNNCells`, and will be replaced by that in Tensorflow 2.0.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/legacy_tf_layers/core.py:171: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
            "  warnings.warn('`tf.layers.dense` is deprecated and '\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer_v1.py:1692: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
            "  warnings.warn('`layer.apply` is deprecated and '\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer_v1.py:1700: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n",
            "  warnings.warn('`layer.add_variable` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/magenta/contrib/rnn.py:474: bidirectional_dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `keras.layers.Bidirectional(keras.layers.RNN(cell))`, which is equivalent to this API\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/rnn.py:447: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
            "INFO:tensorflow:Restoring parameters from gs://download.magenta.tensorflow.org/models/music_vae/colab2/checkpoints/drums_2bar_small.lokl.ckpt\n",
            "INFO:tensorflow:Building MusicVAE model with BidirectionalLstmEncoder, CategoricalLstmDecoder, and hparams:\n",
            "{'max_seq_len': 32, 'z_size': 256, 'free_bits': 48, 'max_beta': 0.2, 'beta_rate': 0.0, 'batch_size': 4, 'grad_clip': 1.0, 'clip_mode': 'global_norm', 'grad_norm_clip_to_zero': 10000, 'learning_rate': 0.001, 'decay_rate': 0.9999, 'min_learning_rate': 1e-05, 'conditional': True, 'dec_rnn_size': [256, 256], 'enc_rnn_size': [512], 'dropout_keep_prob': 1.0, 'sampling_schedule': 'inverse_sigmoid', 'sampling_rate': 1000, 'use_cudnn': False, 'residual_encoder': False, 'residual_decoder': False, 'control_preprocessing_rnn_size': [256]}\n",
            "INFO:tensorflow:\n",
            "Encoder Cells (bidirectional):\n",
            "  units: [512]\n",
            "\n",
            "WARNING:tensorflow:`tf.nn.rnn_cell.MultiRNNCell` is deprecated. This class is equivalent as `tf.keras.layers.StackedRNNCells`, and will be replaced by that in Tensorflow 2.0.\n",
            "WARNING:tensorflow:`tf.nn.rnn_cell.MultiRNNCell` is deprecated. This class is equivalent as `tf.keras.layers.StackedRNNCells`, and will be replaced by that in Tensorflow 2.0.\n",
            "INFO:tensorflow:\n",
            "Decoder Cells:\n",
            "  units: [256, 256]\n",
            "\n",
            "WARNING:tensorflow:Setting non-training sampling schedule from inverse_sigmoid:1000.000000 to constant:1.0.\n",
            "WARNING:tensorflow:`tf.nn.rnn_cell.MultiRNNCell` is deprecated. This class is equivalent as `tf.keras.layers.StackedRNNCells`, and will be replaced by that in Tensorflow 2.0.\n",
            "INFO:tensorflow:Restoring parameters from gs://download.magenta.tensorflow.org/models/music_vae/colab2/checkpoints/drums_2bar_small.hikl.ckpt\n",
            "INFO:tensorflow:Building MusicVAE model with BidirectionalLstmEncoder, MultiLabelRnnNadeDecoder, and hparams:\n",
            "{'max_seq_len': 32, 'z_size': 256, 'free_bits': 48, 'max_beta': 0.2, 'beta_rate': 0.0, 'batch_size': 4, 'grad_clip': 1.0, 'clip_mode': 'global_norm', 'grad_norm_clip_to_zero': 10000, 'learning_rate': 0.001, 'decay_rate': 0.9999, 'min_learning_rate': 1e-05, 'conditional': True, 'dec_rnn_size': [512, 512], 'enc_rnn_size': [1024], 'dropout_keep_prob': 1.0, 'sampling_schedule': 'inverse_sigmoid', 'sampling_rate': 1000, 'use_cudnn': False, 'residual_encoder': False, 'residual_decoder': False, 'control_preprocessing_rnn_size': [256], 'nade_num_hidden': 128}\n",
            "INFO:tensorflow:\n",
            "Encoder Cells (bidirectional):\n",
            "  units: [1024]\n",
            "\n",
            "WARNING:tensorflow:`tf.nn.rnn_cell.MultiRNNCell` is deprecated. This class is equivalent as `tf.keras.layers.StackedRNNCells`, and will be replaced by that in Tensorflow 2.0.\n",
            "WARNING:tensorflow:`tf.nn.rnn_cell.MultiRNNCell` is deprecated. This class is equivalent as `tf.keras.layers.StackedRNNCells`, and will be replaced by that in Tensorflow 2.0.\n",
            "INFO:tensorflow:\n",
            "Decoder Cells:\n",
            "  units: [512, 512]\n",
            "\n",
            "WARNING:tensorflow:Setting non-training sampling schedule from inverse_sigmoid:1000.000000 to constant:1.0.\n",
            "WARNING:tensorflow:`tf.nn.rnn_cell.MultiRNNCell` is deprecated. This class is equivalent as `tf.keras.layers.StackedRNNCells`, and will be replaced by that in Tensorflow 2.0.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206: calling squeeze (from tensorflow.python.ops.array_ops) with squeeze_dims is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use the `axis` argument instead\n",
            "INFO:tensorflow:Restoring parameters from gs://download.magenta.tensorflow.org/models/music_vae/colab2/checkpoints/drums_2bar_nade.reduced.ckpt\n",
            "INFO:tensorflow:Building MusicVAE model with BidirectionalLstmEncoder, MultiLabelRnnNadeDecoder, and hparams:\n",
            "{'max_seq_len': 32, 'z_size': 256, 'free_bits': 48, 'max_beta': 0.2, 'beta_rate': 0.0, 'batch_size': 4, 'grad_clip': 1.0, 'clip_mode': 'global_norm', 'grad_norm_clip_to_zero': 10000, 'learning_rate': 0.001, 'decay_rate': 0.9999, 'min_learning_rate': 1e-05, 'conditional': True, 'dec_rnn_size': [512, 512], 'enc_rnn_size': [1024], 'dropout_keep_prob': 1.0, 'sampling_schedule': 'inverse_sigmoid', 'sampling_rate': 1000, 'use_cudnn': False, 'residual_encoder': False, 'residual_decoder': False, 'control_preprocessing_rnn_size': [256], 'nade_num_hidden': 128}\n",
            "INFO:tensorflow:\n",
            "Encoder Cells (bidirectional):\n",
            "  units: [1024]\n",
            "\n",
            "WARNING:tensorflow:`tf.nn.rnn_cell.MultiRNNCell` is deprecated. This class is equivalent as `tf.keras.layers.StackedRNNCells`, and will be replaced by that in Tensorflow 2.0.\n",
            "WARNING:tensorflow:`tf.nn.rnn_cell.MultiRNNCell` is deprecated. This class is equivalent as `tf.keras.layers.StackedRNNCells`, and will be replaced by that in Tensorflow 2.0.\n",
            "INFO:tensorflow:\n",
            "Decoder Cells:\n",
            "  units: [512, 512]\n",
            "\n",
            "WARNING:tensorflow:Setting non-training sampling schedule from inverse_sigmoid:1000.000000 to constant:1.0.\n",
            "WARNING:tensorflow:`tf.nn.rnn_cell.MultiRNNCell` is deprecated. This class is equivalent as `tf.keras.layers.StackedRNNCells`, and will be replaced by that in Tensorflow 2.0.\n",
            "INFO:tensorflow:Restoring parameters from gs://download.magenta.tensorflow.org/models/music_vae/colab2/checkpoints/drums_2bar_nade.full.ckpt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "77Aew5W5_Tof"
      },
      "source": [
        "# Download & extract midi (1-time only)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5g3jjDIX9kiJ",
        "outputId": "f4c4ec03-e247-44e9-cac3-3dc6e37ffc21"
      },
      "source": [
        "!rm -r audiofiles\n",
        "\n",
        "os.mkdir('audiofiles')\n",
        "!wget --no-check-certificate -r \"https://ollaregang.pythonanywhere.com/static/MIDI/AllDrums.zip\" -O \"audiofiles/Input.zip\" "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rm: cannot remove 'audiofiles': No such file or directory\n",
            "WARNING: combining -O with -r or -p will mean that all downloaded content\n",
            "will be placed in the single file you specified.\n",
            "\n",
            "--2021-05-27 09:06:40--  https://ollaregang.pythonanywhere.com/static/MIDI/AllDrums.zip\n",
            "Resolving ollaregang.pythonanywhere.com (ollaregang.pythonanywhere.com)... 35.173.69.207\n",
            "Connecting to ollaregang.pythonanywhere.com (ollaregang.pythonanywhere.com)|35.173.69.207|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 6812 (6.7K) [application/zip]\n",
            "Saving to: ‘audiofiles/Input.zip’\n",
            "\n",
            "audiofiles/Input.zi 100%[===================>]   6.65K  --.-KB/s    in 0s      \n",
            "\n",
            "2021-05-27 09:06:40 (615 MB/s) - ‘audiofiles/Input.zip’ saved [6812/6812]\n",
            "\n",
            "FINISHED --2021-05-27 09:06:40--\n",
            "Total wall clock time: 0.5s\n",
            "Downloaded: 1 files, 6.7K in 0s (615 MB/s)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ed5jiuB_nVr"
      },
      "source": [
        "from zipfile import ZipFile\n",
        "\n",
        "zipname = \"audiofiles/Input.zip\"\n",
        "with ZipFile(zipname,'r') as zpfile:\n",
        "  files = zpfile.namelist()\n",
        "  for f in files:\n",
        "    if (f.endswith('.mid')):\n",
        "      zpfile.extract(f, 'audiofiles')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RTsrpipz4cFc"
      },
      "source": [
        "# Generate Interpolations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a4uHE57PD5AS"
      },
      "source": [
        "## Load midi files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MnEZ1F7fAx0k"
      },
      "source": [
        "input_drums_midi_data = [\n",
        "    tf.io.gfile.GFile(fn, mode='rb').read()\n",
        "    for fn in sorted(tf.io.gfile.glob('./audiofiles/MIDI_2bar/*.mid'))]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5iWJ86wRJLpq"
      },
      "source": [
        "## convert midi to needed format"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zqCJFtHYb-7A",
        "outputId": "a4c5e594-94f4-464d-8de6-9f282393db5f"
      },
      "source": [
        "from note_seq.protobuf import music_pb2\n",
        "import copy\n",
        "import note_seq\n",
        "\n",
        "os.mkdir('audiofiles/converted_MIDI')\n",
        "os.mkdir('audiofiles/ready_to_upload')\n",
        "\n",
        "drums_input_seqs =music_pb2.NoteSequence();\n",
        "def set_to_drums(ns):\n",
        "  for n in ns.notes:\n",
        "    n.instrument=9\n",
        "    n.is_drum = True\n",
        "  return ns\n",
        "\n",
        "\n",
        "def midi_to_drum_note(input_drums_midi_data):\n",
        "  drums = []\n",
        "  for m in input_drums_midi_data:\n",
        "    drum = mm.midi_to_note_sequence(m)\n",
        "    set_to_drums(drum)\n",
        "    drums.append(drum)\n",
        "  return drums\n",
        "\n",
        "drums_input_seqs = midi_to_drum_note(input_drums_midi_data)\n",
        "#print(drums_input_seqs)\n",
        "#drums_input_seqs = midi_to_note(input_drums_midi_data)\n",
        "#drums_input_seqs = \n",
        "#[mm.midi_to_note_sequence(m) for m in input_drums_midi_data]\n",
        "print(len(drums_input_seqs))\n",
        "\n",
        "for index in range(len(drums_input_seqs)):\n",
        "  # print(seq)\n",
        "  midi_path = \"audiofiles/converted_MIDI/converted_\" + str(index) + \".mid\"\n",
        "  mm.note_sequence_to_midi_file(drums_input_seqs[index], midi_path)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kbW_rDWkJAfX",
        "outputId": "715d50ad-ab2c-4650-cd41-2c5684df456d"
      },
      "source": [
        "input_drums_midi_data = [\n",
        "    tf.io.gfile.GFile(fn, mode='rb').read()\n",
        "    for fn in sorted(tf.io.gfile.glob('./audiofiles/converted_MIDI/*.mid'))]\n",
        "\n",
        "print(input_drums_midi_data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[b'MThd\\x00\\x00\\x00\\x06\\x00\\x01\\x00\\x03\\x00`MTrk\\x00\\x00\\x00\\x1b\\x00\\xffQ\\x03\\x07\\xa1 \\x00\\xffX\\x04\\x04\\x02\\x18\\x08\\x00\\xffX\\x04\\x04\\x02\\x18\\x08\\x01\\xff/\\x00MTrk\\x00\\x00\\x00\\x07\\x00\\xc0\\x00\\x01\\xff/\\x00MTrk\\x00\\x00\\x00\\x86\\x00\\xc9\\x00\\x00\\x99$c\\x00.c\\x18$\\x00\\x00$c\\x18$\\x00\\x00.\\x00\\x00.c0.\\x00\\x00.c0.\\x00\\x00.c0&d\\x00.\\x00\\x00.c0&\\x00\\x00.\\x00\\x00.c0.\\x00\\x00.c0.\\x00\\x00.c0$d\\x00.\\x00\\x00.c0$\\x00\\x00.\\x00\\x00.c0.\\x00\\x00.c0.\\x00\\x00.c0&d\\x00.\\x00\\x00.c0&\\x00\\x00.\\x00\\x00.c0.\\x00\\x00.c0.\\x00\\x00.c0.\\x00\\x01\\xff/\\x00', b'MThd\\x00\\x00\\x00\\x06\\x00\\x01\\x00\\x03\\x00`MTrk\\x00\\x00\\x00\\x1b\\x00\\xffQ\\x03\\x07\\xa1 \\x00\\xffX\\x04\\x04\\x02\\x18\\x08\\x00\\xffX\\x04\\x04\\x02\\x18\\x08\\x01\\xff/\\x00MTrk\\x00\\x00\\x00\\x07\\x00\\xc0\\x00\\x01\\xff/\\x00MTrk\\x00\\x00\\x00\\xbc\\x00\\xc9\\x00\\x00\\x99$d\\x00.d\\x18.\\x00\\x18.7\\x18.\\x00\\x00.d\\x18.\\x00\\x18.7\\x18$\\x00\\x00$d\\x00.\\x00\\x00.d\\x18.\\x00\\x18$\\x00\\x00&d\\x00.7\\x18.\\x00\\x00.d\\x18&\\x00\\x00.\\x000.d\\x18.\\x00\\x18.7\\x18.\\x00\\x00.d\\x18.\\x00\\x00.d\\x18.\\x00\\x18.7\\x18.\\x00\\x00.d\\x18$d\\x00.\\x00\\x18.7\\x18.\\x00\\x00.d\\x18.\\x00\\x18.7\\x18.\\x00\\x00.d\\x18$\\x00\\x00$d\\x00&d\\x00.\\x00\\x00.7\\x06.\\x00\\x12.7\\x06.\\x00\\x06.7\\x06.\\x00\\x06&\\x00\\x00.d\\x18.\\x00\\x18$\\x00\\x00$d\\x00.7\\x18.\\x00\\x00.d\\x18$\\x00\\x00.\\x00\\x01\\xff/\\x00', b'MThd\\x00\\x00\\x00\\x06\\x00\\x01\\x00\\x03\\x00`MTrk\\x00\\x00\\x00\\x1b\\x00\\xffQ\\x03\\x07\\xa1 \\x00\\xffX\\x04\\x04\\x02\\x18\\x08\\x00\\xffX\\x04\\x04\\x02\\x18\\x08\\x01\\xff/\\x00MTrk\\x00\\x00\\x00\\x07\\x00\\xc0\\x00\\x01\\xff/\\x00MTrk\\x00\\x00\\x00\\xb1\\x00\\xc9\\x00\\x00\\x99$h0$\\x00\\x00.k\\x0c.\\x00\\x00.k\\x0c.\\x00\\x00.k\\x0c.\\x00\\x0c.k\\x0c.\\x00\\x00.k\\x0c$h\\x00.\\x00\\x00.l\\x0c.\\x00\\x0c$\\x00\\x00$h\\x00.l\\x0c.\\x00\\x00.l\\x0c$\\x00\\x00.\\x00\\x00.l\\x0c.\\x00\\x00.l\\x0c&h\\x00.\\x00\\x00.l\\x0c.\\x00$&\\x00\\x00.l\\x0c.\\x00\\x00.l\\x0c.\\x00\\x00.l\\x0c.\\x00\\x0c$h\\x00.l\\x0c.\\x00\\x00.l\\x0c$\\x00\\x00$h\\x00.\\x00\\x00.l\\x0c.\\x00\\x0c$\\x00\\x00$h\\x18$\\x00\\x18$h0$\\x00\\x81\\x10&h\\x18$h\\x18$\\x00\\x00&\\x000$h\\x18$\\x00\\x01\\xff/\\x00', b'MThd\\x00\\x00\\x00\\x06\\x00\\x01\\x00\\x03\\x00`MTrk\\x00\\x00\\x00\\x1b\\x00\\xffQ\\x03\\x07\\xa1 \\x00\\xffX\\x04\\x04\\x02\\x18\\x08\\x00\\xffX\\x04\\x04\\x02\\x18\\x08\\x01\\xff/\\x00MTrk\\x00\\x00\\x00\\x07\\x00\\xc0\\x00\\x01\\xff/\\x00MTrk\\x00\\x00\\x00\\xa4\\x00\\xc9\\x00\\x00\\x99$d\\x00.d\\x0c.\\x00\\x00.d\\x0c.\\x00\\x00.d\\x0c.\\x00\\x00.d\\x0c.\\x00\\x00.d\\x0c.\\x00$.d\\x18.\\x00\\x18$\\x00\\x00.d\\x18.\\x00\\x18&d\\x00.d\\x18.\\x00\\x18&\\x00\\x00.d\\x18.\\x00\\x18.d\\x18.\\x00\\x18.d\\x18.\\x00\\x18$d\\x00.d\\x0c.\\x00\\x0c.d\\x0c.\\x00\\x0c.d\\x0c.\\x00$$\\x00\\x00.d\\x18.\\x00\\x18.d\\x18.\\x00\\x18&d\\x00.d\\x18.\\x00\\x18$d\\x00&\\x00\\x00.d\\x18$\\x00\\x00$d\\x00.\\x00\\x18.d\\x18.\\x00\\x18$\\x00\\x00.d\\x18.\\x00\\x01\\xff/\\x00', b'MThd\\x00\\x00\\x00\\x06\\x00\\x01\\x00\\x03\\x00`MTrk\\x00\\x00\\x00\\x1b\\x00\\xffQ\\x03\\x07\\xa1 \\x00\\xffX\\x04\\x04\\x02\\x18\\x08\\x00\\xffX\\x04\\x04\\x02\\x18\\x08\\x01\\xff/\\x00MTrk\\x00\\x00\\x00\\x07\\x00\\xc0\\x00\\x01\\xff/\\x00MTrk\\x00\\x00\\x00\\x86\\x00\\xc9\\x00\\x00\\x99$d\\x00.b0.\\x00\\x00.b0.\\x00\\x00.b0.\\x00\\x00.b\\x18.\\x00\\x00.b\\x18&d\\x00.\\x00\\x00.b0$\\x00\\x00&\\x00\\x00.\\x000.b0.\\x00\\x00.b0.\\x00\\x00.b0.\\x00\\x00.b\\x18.\\x00\\x00.b\\x18$d\\x00.\\x00\\x00.b0.\\x000$\\x00\\x00&d\\x00.b0$d\\x00&\\x00\\x00.\\x00\\x00.b0.\\x00\\x00.b0$\\x00\\x00.\\x00\\x00.b0.\\x00\\x01\\xff/\\x00', b'MThd\\x00\\x00\\x00\\x06\\x00\\x01\\x00\\x03\\x00`MTrk\\x00\\x00\\x00\\x1b\\x00\\xffQ\\x03\\x07\\xa1 \\x00\\xffX\\x04\\x04\\x02\\x18\\x08\\x00\\xffX\\x04\\x04\\x02\\x18\\x08\\x01\\xff/\\x00MTrk\\x00\\x00\\x00\\x07\\x00\\xc0\\x00\\x01\\xff/\\x00MTrk\\x00\\x00\\x00\\x98\\x00\\xc9\\x00\\x00\\x99$d\\x18$\\x00\\x00$d\\x18$\\x00\\x00$d\\x18$\\x00\\x18&d\\x18&\\x00\\x00.a\\x18$d\\x00.\\x00\\x18$\\x00\\x18$a\\x18$\\x00\\x18&a\\x18&\\x00\\x18$a\\x18$\\x00\\x00.a\\x18&a\\x00.\\x00\\x00.a\\x18&\\x00\\x00.\\x00\\x00.a\\x18$d\\x00.\\x00\\x18$\\x00\\x00$d\\x18$\\x00\\x00$d\\x18$\\x00\\x18&d\\x18&\\x00\\x18$d\\x18$\\x00\\x18$a\\x18$\\x00\\x18&a\\x18&\\x00\\x18$a\\x18$\\x00\\x00.a\\x18&a\\x00.\\x00\\x00.a\\x18&\\x00\\x00.\\x00\\x01\\xff/\\x00', b'MThd\\x00\\x00\\x00\\x06\\x00\\x01\\x00\\x03\\x00`MTrk\\x00\\x00\\x00\\x1b\\x00\\xffQ\\x03\\x07\\xa1 \\x00\\xffX\\x04\\x04\\x02\\x18\\x08\\x00\\xffX\\x04\\x04\\x02\\x18\\x08\\x01\\xff/\\x00MTrk\\x00\\x00\\x00\\x07\\x00\\xc0\\x00\\x01\\xff/\\x00MTrk\\x00\\x00\\x00b\\x00\\xc9\\x00\\x00\\x99$a\\x10$\\x00\\x08$a\\x10$\\x008.b\\x18.\\x00\\x00.a\\x0c.\\x00T&a\\x18&\\x00H.a\\x18.\\x000$a\\x18$\\x00\\x00$a\\x18$\\x00H.a\\x0c.\\x00\\x00.a\\x0c.\\x00\\x00.a\\x0c.\\x00\\x00.a\\x0c.\\x00\\x00.a\\x0c.\\x00\\x0c$a\\x0c$\\x00\\x0c&bn&\\x00\\x01\\xff/\\x00', b'MThd\\x00\\x00\\x00\\x06\\x00\\x01\\x00\\x03\\x00`MTrk\\x00\\x00\\x00\\x1b\\x00\\xffQ\\x03\\x07\\xa1 \\x00\\xffX\\x04\\x04\\x02\\x18\\x08\\x00\\xffX\\x04\\x04\\x02\\x18\\x08\\x01\\xff/\\x00MTrk\\x00\\x00\\x00\\x07\\x00\\xc0\\x00\\x01\\xff/\\x00MTrk\\x00\\x00\\x00\\xb0\\x00\\xc9\\x00\\x00\\x99$f\\x00.m\\x0c.\\x00\\x00.m\\x0c.\\x00\\x00.m\\x0c.\\x00\\x00.m\\x0c$\\x00\\x00.\\x00\\x00.m\\x0c.\\x00$.m\\x0c.\\x00$.m\\x0c.\\x00$&f\\x0c.m\\x0c.\\x00\\x18&\\x00\\x18.m\\x0c.\\x00\\x0c$f\\x18.m\\x0c.\\x00\\x0c$\\x00\\x00.n\\x0c.\\x000.n\\x0c.\\x00$.n\\x0c.\\x00\\x0c.n\\x0c$f\\x00.\\x000$\\x00\\x00$f\\x00.n\\x0c.\\x00\\x00.n\\x0c.\\x00\\x00.n\\x0c.\\x00\\x00.n\\x0c$\\x00\\x00&f\\x00.\\x00\\x18.n\\x0c.\\x00\\x0c&\\x000.n\\x0c.\\x00$.n\\x0c.\\x00\\x0c.n\\x0c.\\x00\\x01\\xff/\\x00', b'MThd\\x00\\x00\\x00\\x06\\x00\\x01\\x00\\x03\\x00`MTrk\\x00\\x00\\x00\\x1b\\x00\\xffQ\\x03\\x07\\xa1 \\x00\\xffX\\x04\\x04\\x02\\x18\\x08\\x00\\xffX\\x04\\x04\\x02\\x18\\x08\\x01\\xff/\\x00MTrk\\x00\\x00\\x00\\x07\\x00\\xc0\\x00\\x01\\xff/\\x00MTrk\\x00\\x00\\x00\\x8c\\x00\\xc9\\x00\\x00\\x99$d\\x00.a0$\\x00\\x00.\\x00\\x00.a0.\\x00\\x00.a0.\\x00\\x00.a0&d\\x00.\\x00\\x00.a0&\\x00\\x00.\\x000.a0.\\x00\\x00.a0$d\\x00.\\x00\\x00.a\\x18.\\x00\\x00.a\\x18$\\x00\\x00.\\x00\\x00.a0.\\x00\\x00.a0.\\x00\\x00.a0&a\\x00.\\x00\\x00.a\\x18.\\x00\\x00.a\\x18&\\x00\\x00.\\x00\\x00.a0.\\x00\\x00.a\\x18.\\x00\\x00.a\\x18.\\x00\\x00.a0.\\x00\\x01\\xff/\\x00', b'MThd\\x00\\x00\\x00\\x06\\x00\\x01\\x00\\x03\\x00`MTrk\\x00\\x00\\x00\\x1b\\x00\\xffQ\\x03\\x07\\xa1 \\x00\\xffX\\x04\\x04\\x02\\x18\\x08\\x00\\xffX\\x04\\x04\\x02\\x18\\x08\\x01\\xff/\\x00MTrk\\x00\\x00\\x00\\x07\\x00\\xc0\\x00\\x01\\xff/\\x00MTrk\\x00\\x00\\x00t\\x00\\xc9\\x00\\x00\\x99$d`$\\x00\\x00&R\\x00.Q\\x18.\\x00\\x00.Q\\x18.\\x000$d\\x00&\\x00\\x18$\\x00\\x00$d\\x18$\\x00\\x00.X\\x18.\\x00\\x18&d0$c\\x00&\\x000$\\x00\\x00$d`$\\x00\\x00.E\\x18.\\x00\\x18&E0&\\x00\\x18.U\\x0c.\\x00\\x00.U\\x0c.\\x00\\x00.R\\x0c.\\x00\\x00.R\\x0c.\\x00\\x18&X0$c\\x00&\\x000$\\x00\\x01\\xff/\\x00']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dac1r3kAJUaX"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 767
        },
        "id": "ilS5cJslHWcm",
        "outputId": "e22fc73e-e9bc-4233-ca2a-64b32490d8fc"
      },
      "source": [
        "drums_input_seqs = [mm.midi_to_sequence_proto(m) for m in input_drums_midi_data]\n",
        "\n",
        "extracted_beats = [];\n",
        "for ns in drums_input_seqs:\n",
        "\n",
        "  test=drums_nade_full_config.data_converter.from_tensors(\n",
        "      drums_nade_full_config.data_converter.to_tensors(ns)[1])\n",
        "  extracted_beats.extend(test)\n",
        "  #print(test)\n",
        "for index, beat in enumerate(extracted_beats):\n",
        "  print(\"Beat\", index)\n",
        "  play(beat)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Beat 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div id=\"id_1\"> </div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Beat 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div id=\"id_2\"> </div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Beat 2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div id=\"id_3\"> </div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Beat 3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div id=\"id_4\"> </div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Beat 4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div id=\"id_5\"> </div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Beat 5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div id=\"id_6\"> </div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Beat 6\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div id=\"id_7\"> </div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Beat 7\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div id=\"id_8\"> </div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Beat 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div id=\"id_9\"> </div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Beat 9\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div id=\"id_10\"> </div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N0nNsM7yKR1b"
      },
      "source": [
        "## interpolation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MeAboOS1xDgE"
      },
      "source": [
        "import requests\n",
        "\n",
        "alphabet = [\"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\", \"H\", \"I\", \"J\"]\n",
        "\n",
        "drums_interp_model = \"drums_2bar_oh_hikl\" \n",
        "\n",
        "\n",
        "\n",
        "# temperature = 0.8 #@param {type:\"slider\", min:0.1, max:1.5, step:0.1}\n",
        "temperature = 0.5\n",
        "num_steps = 8 \n",
        "\n",
        "for index1, beat1 in enumerate(extracted_beats):\n",
        "  for index2, beat2 in enumerate(extracted_beats):\n",
        "    start_beat = extracted_beats[index1]\n",
        "    end_beat = extracted_beats[index2]\n",
        "    drums_interp = interpolate(drums_models[drums_interp_model],\n",
        "                              start_beat, \n",
        "                              end_beat, \n",
        "                              num_steps=num_steps, \n",
        "                              temperature=temperature)\n",
        "    mm.sequence_proto_to_midi_file(drums_interp, \"audiofiles/ready_to_upload/interpolation_\" + str(index1) + str(index2) + \".mid\")\n",
        "    url = 'http://OLLAREGANG.pythonanywhere.com/interpolationUploader/interpolation_' + alphabet[index1] + alphabet[index2] + \".mid\"\n",
        "    midiToUpload = open('audiofiles/ready_to_upload/interpolation_' + str(index1) + str(index2) + \".mid\", 'rb')\n",
        "    x = requests.post(url, data = midiToUpload)\n",
        "    print(x.text)\n",
        "    # download(drums_interp, \"audiofiles/ready_to_upload/interpolation_\" + alphabet[index1] + alphabet[index2] + \".mid\")\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}